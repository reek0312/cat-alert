{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T06:58:48.417716Z",
     "iopub.status.busy": "2024-12-17T06:58:48.417353Z",
     "iopub.status.idle": "2024-12-17T06:59:01.514166Z",
     "shell.execute_reply": "2024-12-17T06:59:01.513321Z",
     "shell.execute_reply.started": "2024-12-17T06:58:48.417679Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 17075, done.\u001b[K\n",
      "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 17075 (delta 29), reused 29 (delta 12), pack-reused 17022 (from 1)\u001b[K\n",
      "Receiving objects: 100% (17075/17075), 15.69 MiB | 33.83 MiB/s, done.\n",
      "Resolving deltas: 100% (11723/11723), done.\n",
      "/kaggle/working/yolov5\n",
      "Requirement already satisfied: gitpython>=3.1.30 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.1.43)\n",
      "Requirement already satisfied: matplotlib>=3.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (3.7.5)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=10.3.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (10.3.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (5.9.3)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.14.1)\n",
      "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.4.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.19.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (4.66.4)\n",
      "Collecting ultralytics>=8.2.34 (from -r requirements.txt (line 18))\n",
      "  Downloading ultralytics-8.3.50-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 27)) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=70.0.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 42)) (70.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.11)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2024.6.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2024.6.0)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics>=8.2.34->-r requirements.txt (line 18)) (9.0.0)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.34->-r requirements.txt (line 18))\n",
      "  Downloading ultralytics_thop-2.0.13-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2024.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
      "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Downloading ultralytics-8.3.50-py3-none-any.whl (898 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m899.0/899.0 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.13-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: ultralytics-thop, thop, ultralytics\n",
      "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.3.50 ultralytics-thop-2.0.13\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T06:59:12.434054Z",
     "iopub.status.busy": "2024-12-17T06:59:12.433261Z",
     "iopub.status.idle": "2024-12-17T06:59:13.430770Z",
     "shell.execute_reply": "2024-12-17T06:59:13.429780Z",
     "shell.execute_reply.started": "2024-12-17T06:59:12.434019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp /kaggle/input/cat-detection/custom.yaml /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T06:59:16.822112Z",
     "iopub.status.busy": "2024-12-17T06:59:16.821741Z",
     "iopub.status.idle": "2024-12-17T06:59:21.000552Z",
     "shell.execute_reply": "2024-12-17T06:59:20.999641Z",
     "shell.execute_reply.started": "2024-12-17T06:59:16.822080Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/cat-detection/training_data /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T06:59:38.053099Z",
     "iopub.status.busy": "2024-12-17T06:59:38.052747Z",
     "iopub.status.idle": "2024-12-17T06:59:39.045530Z",
     "shell.execute_reply": "2024-12-17T06:59:39.044522Z",
     "shell.execute_reply.started": "2024-12-17T06:59:38.053067Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: /kaggle/working/training_data/images/train\n",
      "val: /kaggle/working/training_data/images/val\n",
      "\n",
      "nc: 1\n",
      "names: ['Cat']"
     ]
    }
   ],
   "source": [
    "!cat /kaggle/working/custom.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-12-17T06:59:55.698793Z",
     "iopub.status.busy": "2024-12-17T06:59:55.698429Z",
     "iopub.status.idle": "2024-12-17T07:10:29.936186Z",
     "shell.execute_reply": "2024-12-17T07:10:29.935068Z",
     "shell.execute_reply.started": "2024-12-17T06:59:55.698763Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ⚠️ wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=/kaggle/working/custom.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=32, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=data/hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=6, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
      "100%|████████████████████████████████████████| 755k/755k [00:00<00:00, 25.9MB/s]\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
      "100%|███████████████████████████████████████| 14.1M/14.1M [00:00<00:00, 151MB/s]\n",
      "\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 343/349 items from yolov5s.pt\n",
      "/kaggle/working/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "/kaggle/working/yolov5/models/common.py:892: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "WARNING ⚠️ DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n",
      "See Multi-GPU Tutorial at https://docs.ultralytics.com/yolov5/tutorials/multi_gpu_training to get started.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/training_data/labels/train... 88 images, 0 backg\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/43.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/44.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/45.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/46.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/47.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/48.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/49.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/50.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/52.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/71.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/72.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/73.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/74.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/75.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/76.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/77.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/78.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/79.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/80.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/81.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/86.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/87.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/train/88.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/training_data/labels/train.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/training_data/labels/val... 14 images, 0 backgroun\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/1.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/10.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/11.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/12.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/13.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/14.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/3.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/4.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/5.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/6.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/7.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/8.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/9.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/training_data/labels/val.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.48 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
      "Plotting labels to runs/train/exp/labels.jpg... \n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n",
      "/kaggle/working/yolov5/train.py:355: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]/kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "       0/49      13.2G     0.1245     0.1087          0         88       1280:  /kaggle/working/yolov5/train.py:412: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(amp):\n",
      "/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "       0/49      13.2G     0.1241     0.1045          0         67       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24    0.00133     0.0833   0.000996   0.000235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       1/49      13.2G     0.1224    0.09133          0         61       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24   0.000952     0.0833    0.00156   0.000261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       2/49      13.2G     0.1175    0.07253          0         72       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24     0.0019      0.167    0.00205   0.000345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       3/49      13.2G     0.1075    0.05903          0         65       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.200s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24    0.00333      0.375    0.00277   0.000736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       4/49      13.2G    0.09818    0.05041          0         63       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24    0.00429       0.75    0.00689    0.00188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       5/49      13.2G    0.09305    0.04189          0         61       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.005      0.875     0.0158    0.00447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       6/49      13.2G    0.08683    0.04174          0         74       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24    0.00548      0.958     0.0506      0.016\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       7/49      13.2G    0.07955    0.03988          0         78       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24    0.00571          1      0.256     0.0785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       8/49      13.2G    0.06758    0.03233          0         57       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24     0.0211          1      0.506      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "       9/49      13.2G     0.0665    0.03399          0         72       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.426      0.875      0.648      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      10/49      13.2G     0.0648    0.03224          0         65       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.571      0.458      0.559      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      11/49      13.2G    0.05938    0.02883          0         66       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.229      0.544      0.246     0.0947\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      12/49      13.2G     0.0653    0.02796          0         70       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.552      0.792      0.704      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      13/49      13.2G    0.05911    0.02595          0         64       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.392      0.792      0.445      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      14/49      13.2G    0.05801    0.02646          0         69       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.523       0.75       0.61      0.238\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      15/49      13.2G    0.06025    0.02757          0         70       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.715       0.75       0.79      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      16/49      13.2G    0.05669    0.02401          0         66       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.528      0.747      0.673      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      17/49      13.2G    0.05649    0.02693          0         61       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24       0.54       0.75      0.719      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      18/49      13.2G    0.05263    0.02279          0         62       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.471       0.75      0.622      0.231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      19/49      13.2G    0.05557     0.0242          0         64       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.541      0.738      0.697      0.244\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      20/49      13.2G    0.05406     0.0218          0         66       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.752      0.917      0.858      0.339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      21/49      13.2G    0.05297    0.02239          0         52       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24       0.73      0.917      0.837       0.49\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      22/49      13.2G    0.05262    0.02406          0         57       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.159      0.631       0.16     0.0514\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      23/49      13.2G    0.05505    0.02239          0         70       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.549      0.812      0.726      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      24/49      13.2G    0.05433     0.0198          0         57       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.734      0.792      0.827      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      25/49      13.2G    0.05324     0.0238          0         72       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.847      0.833      0.851      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      26/49      13.2G    0.04792    0.01843          0         58       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.645      0.792      0.739      0.227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      27/49      13.2G    0.04932    0.02334          0         73       1280: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.671      0.792      0.725      0.278\n",
      "Stopping training early as no improvement observed in last 6 epochs. Best results observed at epoch 21, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=6) pass a new patience value, i.e. `python train.py --patience 300` or use `--patience 0` to disable EarlyStopping.\n",
      "\n",
      "28 epochs completed in 0.151 hours.\n",
      "Optimizer stripped from runs/train/exp/weights/last.pt, 14.9MB\n",
      "Optimizer stripped from runs/train/exp/weights/best.pt, 14.9MB\n",
      "\n",
      "Validating runs/train/exp/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24       0.73      0.917      0.837       0.49\n",
      "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 1280 --batch 32 --epochs 50 --data /kaggle/working/custom.yaml --weights yolov5s.pt --patience 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T07:11:30.907707Z",
     "iopub.status.busy": "2024-12-17T07:11:30.907337Z",
     "iopub.status.idle": "2024-12-17T07:11:52.280322Z",
     "shell.execute_reply": "2024-12-17T07:11:52.279278Z",
     "shell.execute_reply.started": "2024-12-17T07:11:30.907676Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/kaggle/working/custom.yaml, weights=['runs/train/exp/weights/best.pt'], batch_size=32, imgsz=1280, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 🚀 v7.0-389-ge62a31b6 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/training_data/labels/val.cache... 14 images, 0 bac\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/1.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/10.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/11.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/12.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/13.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/14.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/2.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/3.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/4.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/5.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/6.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/7.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/8.jpg: corrupt JPEG restored and saved\n",
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ /kaggle/working/training_data/images/val/9.jpg: corrupt JPEG restored and saved\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all         14         24      0.731      0.917      0.837      0.491\n",
      "Speed: 4.5ms pre-process, 22.9ms inference, 21.7ms NMS per image at shape (32, 3, 1280, 1280)\n",
      "Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python val.py --data /kaggle/working/custom.yaml --weights runs/train/exp/weights/best.pt --img 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T07:50:17.109762Z",
     "iopub.status.busy": "2024-12-17T07:50:17.108964Z",
     "iopub.status.idle": "2024-12-17T07:50:18.142556Z",
     "shell.execute_reply": "2024-12-17T07:50:18.141236Z",
     "shell.execute_reply.started": "2024-12-17T07:50:17.109726Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#showing some issue with finding best.pt so moving it to working directory(yolov5)\n",
    "\n",
    "!cp /kaggle/input/weights/best.pt /kaggle/working/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________________________________________________\n",
    "\n",
    "**\"Note: If you're using saved weights (best.pt) on a Windows system, you might encounter a 'PosixPath' issue. See the README for details.\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T08:16:58.440034Z",
     "iopub.status.busy": "2024-12-17T08:16:58.439232Z",
     "iopub.status.idle": "2024-12-17T08:16:58.478096Z",
     "shell.execute_reply": "2024-12-17T08:16:58.477336Z",
     "shell.execute_reply.started": "2024-12-17T08:16:58.439997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt: {'weights': 'yolov5s.pt', 'cfg': '', 'data': '/kaggle/working/custom.yaml', 'hyp': {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}, 'epochs': 50, 'batch_size': 32, 'imgsz': 1280, 'rect': False, 'resume': False, 'nosave': False, 'noval': False, 'noautoanchor': False, 'noplots': False, 'evolve': None, 'evolve_population': PosixPath('data/hyps'), 'resume_evolve': None, 'bucket': '', 'cache': None, 'image_weights': False, 'device': '', 'multi_scale': False, 'single_cls': False, 'optimizer': 'SGD', 'sync_bn': False, 'workers': 8, 'project': 'runs/train', 'name': 'exp', 'exist_ok': False, 'quad': False, 'cos_lr': False, 'label_smoothing': 0.0, 'patience': 6, 'freeze': [0], 'save_period': -1, 'seed': 0, 'local_rank': -1, 'entity': None, 'upload_dataset': False, 'bbox_interval': -1, 'artifact_alias': 'latest', 'ndjson_console': False, 'ndjson_file': False, 'save_dir': 'runs/train/exp'}\n",
      "model.yaml: {'nc': 1, 'depth_multiple': 0.33, 'width_multiple': 0.5, 'anchors': [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], 'backbone': [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]], 'head': [[-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 14], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 10], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[17, 20, 23], 1, 'Detect', ['nc', 'anchors']]], 'ch': 3}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the original weights on the CPU(my machine dont have a gpu anyway)\n",
    "checkpoint = torch.load(\"best.pt\", map_location=\"cpu\")\n",
    "\n",
    "# Inspecting 'opt' and 'model.yaml' for PosixPath\n",
    "print(\"opt:\", checkpoint.get(\"opt\"))\n",
    "print(\"model.yaml:\", getattr(checkpoint[\"model\"], \"yaml\", None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-17T08:20:23.201260Z",
     "iopub.status.busy": "2024-12-17T08:20:23.200651Z",
     "iopub.status.idle": "2024-12-17T08:20:23.291173Z",
     "shell.execute_reply": "2024-12-17T08:20:23.290068Z",
     "shell.execute_reply.started": "2024-12-17T08:20:23.201223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed checkpoint saved as best_fixed.pt\n"
     ]
    }
   ],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(\"best.pt\", map_location=\"cpu\")\n",
    "\n",
    "# Clean 'opt'\n",
    "if \"opt\" in checkpoint:\n",
    "    checkpoint[\"opt\"] = {\n",
    "        k: str(v) if isinstance(v, Path) else v  # Convert PosixPath to string\n",
    "        for k, v in checkpoint[\"opt\"].items()\n",
    "    }\n",
    "\n",
    "# Clean 'model.yaml' if necessary\n",
    "if \"model\" in checkpoint and hasattr(checkpoint[\"model\"], \"yaml\"):\n",
    "    checkpoint[\"model\"].yaml = {\n",
    "        k: str(v) if isinstance(v, Path) else v\n",
    "        for k, v in checkpoint[\"model\"].yaml.items()\n",
    "    }\n",
    "\n",
    "# Save the fixed checkpoint\n",
    "torch.save(checkpoint, \"best_fixed.pt\")\n",
    "print(\"Fixed checkpoint saved as best_fixed.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6300604,
     "sourceId": 10196959,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6313605,
     "sourceId": 10214716,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6320203,
     "sourceId": 10223465,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
